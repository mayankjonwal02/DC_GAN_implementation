{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        is_downsampling: bool = True,\n",
    "        add_activation: bool = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if is_downsampling:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True) if add_activation else nn.Identity(),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True) if add_activation else nn.Identity(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels: int):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvolutionalBlock(channels, channels, add_activation=True, kernel_size=3, padding=1),\n",
    "            ConvolutionalBlock(channels, channels, add_activation=False, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self, img_channels: int, num_features: int = 64, num_residuals: int = 6\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generator consists of 2 layers of downsampling/encoding layer, \n",
    "        followed by 6 residual blocks for 128 × 128 training images \n",
    "        and then 3 upsampling/decoding layer. \n",
    "        \n",
    "        The network with 6 residual blocks can be written as: \n",
    "        c7s1–64, d128, d256, R256, R256, R256, R256, R256, R256, u128, u64, and c7s1–3.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.initial_layer = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                img_channels,\n",
    "                num_features,\n",
    "                kernel_size=7,\n",
    "                stride=1,\n",
    "                padding=3,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.downsampling_layers = nn.ModuleList(\n",
    "            [\n",
    "                ConvolutionalBlock(\n",
    "                    num_features, \n",
    "                    num_features * 2,\n",
    "                    is_downsampling=True, \n",
    "                    kernel_size=3, \n",
    "                    stride=2, \n",
    "                    padding=1,\n",
    "                ),\n",
    "                ConvolutionalBlock(\n",
    "                    num_features * 2,\n",
    "                    num_features * 4,\n",
    "                    is_downsampling=True,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.residual_layers = nn.Sequential(\n",
    "            *[ResidualBlock(num_features * 4) for _ in range(num_residuals)]\n",
    "        )\n",
    "\n",
    "        self.upsampling_layers = nn.ModuleList(\n",
    "            [\n",
    "                ConvolutionalBlock(\n",
    "                    num_features * 4,\n",
    "                    num_features * 2,\n",
    "                    is_downsampling=False,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    output_padding=1,\n",
    "                ),\n",
    "                ConvolutionalBlock(\n",
    "                    num_features * 2,\n",
    "                    num_features * 1,\n",
    "                    is_downsampling=False,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    output_padding=1,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.last_layer = nn.Conv2d(\n",
    "            num_features * 1,\n",
    "            img_channels,\n",
    "            kernel_size=7,\n",
    "            stride=1,\n",
    "            padding=3,\n",
    "            padding_mode=\"reflect\",\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_layer(x)\n",
    "        for layer in self.downsampling_layers:\n",
    "            x = layer(x)\n",
    "        x = self.residual_layers(x)\n",
    "        for layer in self.upsampling_layers:\n",
    "            x = layer(x)\n",
    "        return torch.tanh(self.last_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial_layer = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                features[0],\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                nn.ConvInstanceNormLeakyReLUBlock(\n",
    "                    in_channels, \n",
    "                    feature, \n",
    "                    stride=1 if feature == features[-1] else 2,\n",
    "                )\n",
    "            )\n",
    "            in_channels = feature\n",
    " \n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                1,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                padding_mode=\"reflect\",\n",
    "            )\n",
    "        )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
